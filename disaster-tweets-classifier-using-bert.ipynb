{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow --quiet\n!pip install tensorflow-hub --quiet\n!pip install tensorflow-text --quiet\n!pip install transformers --quiet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-17T11:41:03.411399Z","iopub.execute_input":"2023-07-17T11:41:03.411739Z","iopub.status.idle":"2023-07-17T11:41:34.673481Z","shell.execute_reply.started":"2023-07-17T11:41:03.411712Z","shell.execute_reply":"2023-07-17T11:41:34.672281Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import os, re, random\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_text as text\n\ntf.get_logger().setLevel('ERROR')\npd.set_option('display.max_colwidth', None)\nos.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"","metadata":{"execution":{"iopub.status.busy":"2023-07-17T11:41:36.492436Z","iopub.execute_input":"2023-07-17T11:41:36.493386Z","iopub.status.idle":"2023-07-17T11:42:16.741010Z","shell.execute_reply.started":"2023-07-17T11:41:36.493349Z","shell.execute_reply":"2023-07-17T11:42:16.740110Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"D0717 11:42:08.187644679     171 config.cc:119]                        gRPC EXPERIMENT tcp_frame_size_tuning               OFF (default:OFF)\nD0717 11:42:08.187683005     171 config.cc:119]                        gRPC EXPERIMENT tcp_rcv_lowat                       OFF (default:OFF)\nD0717 11:42:08.187686540     171 config.cc:119]                        gRPC EXPERIMENT peer_state_based_framing            OFF (default:OFF)\nD0717 11:42:08.187689222     171 config.cc:119]                        gRPC EXPERIMENT flow_control_fixes                  ON  (default:ON)\nD0717 11:42:08.187692198     171 config.cc:119]                        gRPC EXPERIMENT memory_pressure_controller          OFF (default:OFF)\nD0717 11:42:08.187695241     171 config.cc:119]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size OFF (default:OFF)\nD0717 11:42:08.187697832     171 config.cc:119]                        gRPC EXPERIMENT new_hpack_huffman_decoder           ON  (default:ON)\nD0717 11:42:08.187701110     171 config.cc:119]                        gRPC EXPERIMENT event_engine_client                 OFF (default:OFF)\nD0717 11:42:08.187703712     171 config.cc:119]                        gRPC EXPERIMENT monitoring_experiment               ON  (default:ON)\nD0717 11:42:08.187706226     171 config.cc:119]                        gRPC EXPERIMENT promise_based_client_call           OFF (default:OFF)\nD0717 11:42:08.187709193     171 config.cc:119]                        gRPC EXPERIMENT free_large_allocator                OFF (default:OFF)\nD0717 11:42:08.187717381     171 config.cc:119]                        gRPC EXPERIMENT promise_based_server_call           OFF (default:OFF)\nD0717 11:42:08.187720226     171 config.cc:119]                        gRPC EXPERIMENT transport_supplies_client_latency   OFF (default:OFF)\nD0717 11:42:08.187722795     171 config.cc:119]                        gRPC EXPERIMENT event_engine_listener               OFF (default:OFF)\nI0717 11:42:08.187918978     171 ev_epoll1_linux.cc:122]               grpc epoll fd: 62\nD0717 11:42:08.187931360     171 ev_posix.cc:144]                      Using polling engine: epoll1\nD0717 11:42:08.187966638     171 dns_resolver_ares.cc:822]             Using ares dns resolver\nD0717 11:42:08.196591176     171 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD0717 11:42:08.196604899     171 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD0717 11:42:08.196609051     171 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD0717 11:42:08.196611982     171 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD0717 11:42:08.196615158     171 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD0717 11:42:08.196618309     171 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin_experimental\"\nD0717 11:42:08.196625143     171 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD0717 11:42:08.196640968     171 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD0717 11:42:08.196668938     171 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD0717 11:42:08.196681504     171 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD0717 11:42:08.196685523     171 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD0717 11:42:08.196688629     171 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD0717 11:42:08.196695067     171 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_resolver_experimental\"\nD0717 11:42:08.196698378     171 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD0717 11:42:08.196702015     171 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD0717 11:42:08.196706263     171 certificate_provider_registry.cc:35]  registering certificate provider factory for \"file_watcher\"\nI0717 11:42:08.199605540     171 socket_utils_common_posix.cc:408]     Disabling AF_INET6 sockets because ::1 is not available.\nI0717 11:42:08.212881669     171 socket_utils_common_posix.cc:337]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE0717 11:42:08.221169994     171 oauth2_credentials.cc:236]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {grpc_status:2, created_time:\"2023-07-17T11:42:08.221154292+00:00\"}\n","output_type":"stream"}]},{"cell_type":"code","source":"# CHANGED FOR TPU 1VM:\n# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu=\"local\") # \"local\" for 1VM TPU\n    strategy = tf.distribute.TPUStrategy(tpu)\n    print(\"on TPU\")\nexcept tf.errors.NotFoundError:\n    print(\"not on TPU\")\n    strategy = tf.distribute.MirroredStrategy()\n    \nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T11:42:29.146801Z","iopub.execute_input":"2023-07-17T11:42:29.147229Z","iopub.status.idle":"2023-07-17T11:42:34.207678Z","shell.execute_reply.started":"2023-07-17T11:42:29.147182Z","shell.execute_reply":"2023-07-17T11:42:34.206535Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"on TPU\nREPLICAS:  8\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Import Dataset","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-07-17T11:42:37.485346Z","iopub.execute_input":"2023-07-17T11:42:37.485713Z","iopub.status.idle":"2023-07-17T11:42:37.554815Z","shell.execute_reply.started":"2023-07-17T11:42:37.485685Z","shell.execute_reply":"2023-07-17T11:42:37.553582Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2023-07-17T11:42:39.297054Z","iopub.execute_input":"2023-07-17T11:42:39.297478Z","iopub.status.idle":"2023-07-17T11:42:39.307253Z","shell.execute_reply.started":"2023-07-17T11:42:39.297445Z","shell.execute_reply":"2023-07-17T11:42:39.306276Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Index(['id', 'keyword', 'location', 'text', 'target'], dtype='object')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Exploratory Data Analysis (EDA)","metadata":{}},{"cell_type":"markdown","source":"First, let's check if there are any mislabeled tweets inside the dataset. As we cannot manually inspect all tweets to see if the tweets have been correctly classifier, we are going to look for duplicate tweets and check that duplicates have been assigned to the same labels. ","metadata":{}},{"cell_type":"code","source":"duplicates = train[train.duplicated('text')]\nduplicates.text.nunique()","metadata":{"execution":{"iopub.status.busy":"2023-07-17T11:42:41.892186Z","iopub.execute_input":"2023-07-17T11:42:41.892567Z","iopub.status.idle":"2023-07-17T11:42:41.901839Z","shell.execute_reply.started":"2023-07-17T11:42:41.892538Z","shell.execute_reply":"2023-07-17T11:42:41.900926Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"69"},"metadata":{}}]},{"cell_type":"markdown","source":"There are 69 duplicate tweets inside the training dataset. We are going to iterate through these duplicate tweets to see if these duplicate tweets have unmatching labels. Unmatching labels would indicate that the tweet(s) has been mislabeled. We are going to store the index of these \"problematic duplicates\" inside a list and use it to iterature through these tweets so that we can re-assigned the correct labels after inspecting them.","metadata":{}},{"cell_type":"code","source":"problematic_duplicates = []\n\nfor i in range(duplicates.text.nunique()):\n    duplicate_subset = train[train.text == duplicates.text.unique()[i]]\n    if len(duplicate_subset) > 1 and duplicate_subset.target.nunique() == 2:\n        problematic_duplicates.append(i)\n        \nprint(problematic_duplicates)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T11:42:44.251183Z","iopub.execute_input":"2023-07-17T11:42:44.252251Z","iopub.status.idle":"2023-07-17T11:42:44.346100Z","shell.execute_reply.started":"2023-07-17T11:42:44.252197Z","shell.execute_reply":"2023-07-17T11:42:44.345088Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"[4, 7, 12, 15, 24, 26, 33, 34, 35, 36, 38, 39, 42, 44, 46, 51, 55, 58]\n","output_type":"stream"}]},{"cell_type":"code","source":"train[train.text == duplicates.text.unique()[58]]","metadata":{"execution":{"iopub.status.busy":"2023-07-17T11:42:47.444695Z","iopub.execute_input":"2023-07-17T11:42:47.445134Z","iopub.status.idle":"2023-07-17T11:42:47.461456Z","shell.execute_reply.started":"2023-07-17T11:42:47.445101Z","shell.execute_reply":"2023-07-17T11:42:47.460261Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"        id    keyword              location  \\\n6614  9470  terrorism  Jeddah_Saudi Arabia.   \n6616  9472  terrorism                Riyadh   \n\n                                                                                                        text  \\\n6614  In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!   \n6616  In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!   \n\n      target  \n6614       0  \n6616       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6614</th>\n      <td>9470</td>\n      <td>terrorism</td>\n      <td>Jeddah_Saudi Arabia.</td>\n      <td>In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6616</th>\n      <td>9472</td>\n      <td>terrorism</td>\n      <td>Riyadh</td>\n      <td>In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Above is the 58th duplicate. We see that these tweets have unmatching labels despite their texts being identical. This tweet is not about an actual disaster, so we are going to correctly assign both tweets as not being about an actual disaster. This is going to look like this: ","metadata":{}},{"cell_type":"code","source":"train.target = np.where(train.text == duplicates.text.unique()[58], 0, train.target)\ntrain[train.text == duplicates.text.unique()[58]]","metadata":{"execution":{"iopub.status.busy":"2023-07-17T11:42:50.306555Z","iopub.execute_input":"2023-07-17T11:42:50.306932Z","iopub.status.idle":"2023-07-17T11:42:50.323117Z","shell.execute_reply.started":"2023-07-17T11:42:50.306904Z","shell.execute_reply":"2023-07-17T11:42:50.321867Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"        id    keyword              location  \\\n6614  9470  terrorism  Jeddah_Saudi Arabia.   \n6616  9472  terrorism                Riyadh   \n\n                                                                                                        text  \\\n6614  In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!   \n6616  In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!   \n\n      target  \n6614       0  \n6616       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6614</th>\n      <td>9470</td>\n      <td>terrorism</td>\n      <td>Jeddah_Saudi Arabia.</td>\n      <td>In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6616</th>\n      <td>9472</td>\n      <td>terrorism</td>\n      <td>Riyadh</td>\n      <td>In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's repeat this task for all problematic duplicates after having identified the correct labels for each and every one of these problematic duplicates. We are going to store the correct labels inside a list and iterate through the problematic duplicates, assigning the correct labels one after the other.","metadata":{}},{"cell_type":"code","source":"target_list = [0,0,0,0,1,0,0,0,1,0,0,0,0,0,1,1,0,0]\n\nfor problematic_index in range(len(problematic_duplicates)): \n    train.target = np.where(train.text == duplicates.text.unique()[problematic_index], \n                            target_list[problematic_index], train.target)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T11:42:53.326451Z","iopub.execute_input":"2023-07-17T11:42:53.326823Z","iopub.status.idle":"2023-07-17T11:42:53.355873Z","shell.execute_reply.started":"2023-07-17T11:42:53.326795Z","shell.execute_reply":"2023-07-17T11:42:53.354544Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing the Text","metadata":{}},{"cell_type":"markdown","source":"Before we use the text as input, we are going to perform some basic pre-processing. To identify the appropriate steps, let's look at some of the tweets.","metadata":{}},{"cell_type":"code","source":"random.seed(1048596)\nsample_train = train.sample(frac = 1).head(5)\nsample_train","metadata":{"execution":{"iopub.status.busy":"2023-07-17T11:42:57.304818Z","iopub.execute_input":"2023-07-17T11:42:57.305198Z","iopub.status.idle":"2023-07-17T11:42:57.319395Z","shell.execute_reply.started":"2023-07-17T11:42:57.305167Z","shell.execute_reply":"2023-07-17T11:42:57.318270Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"        id      keyword       location  \\\n4277  6075  heat%20wave     liverpool    \n6306  9009    stretcher            NaN   \n1075  1554         bomb            NaN   \n4011  5695       floods            NaN   \n4213  5985    hazardous  Nashville, Tn   \n\n                                                                                                                 text  \\\n4277  #greatbritishbakeoff love to know where I was when all this nice weather happened! Did miss the heat wave ?? ??   \n6306                                                         How to Freeze Fruits and Veggies\\nhttp://t.co/MET0mtpr3S   \n1075                          New Documents Found Pointing To Japan's WWII Atomic Bomb Program http://t.co/M9mowCMVNj   \n4011                Children in Myanmar face a 'double catastrophe' as floods hit the most ... http://t.co/0jFNvAXFph   \n4213        Wholesale #WE Gon Rep That $hit At All Costs- Hazardous #WholeTeam3 #WholesaleEnt https://t.co/JWnXH9Q5ov   \n\n      target  \n4277       0  \n6306       0  \n1075       1  \n4011       1  \n4213       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4277</th>\n      <td>6075</td>\n      <td>heat%20wave</td>\n      <td>liverpool</td>\n      <td>#greatbritishbakeoff love to know where I was when all this nice weather happened! Did miss the heat wave ?? ??</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6306</th>\n      <td>9009</td>\n      <td>stretcher</td>\n      <td>NaN</td>\n      <td>How to Freeze Fruits and Veggies\\nhttp://t.co/MET0mtpr3S</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1075</th>\n      <td>1554</td>\n      <td>bomb</td>\n      <td>NaN</td>\n      <td>New Documents Found Pointing To Japan's WWII Atomic Bomb Program http://t.co/M9mowCMVNj</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4011</th>\n      <td>5695</td>\n      <td>floods</td>\n      <td>NaN</td>\n      <td>Children in Myanmar face a 'double catastrophe' as floods hit the most ... http://t.co/0jFNvAXFph</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4213</th>\n      <td>5985</td>\n      <td>hazardous</td>\n      <td>Nashville, Tn</td>\n      <td>Wholesale #WE Gon Rep That $hit At All Costs- Hazardous #WholeTeam3 #WholesaleEnt https://t.co/JWnXH9Q5ov</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"In the randomly selected tweets above, we see that the tweets contain links (http://...), hashtags (#..), and mentions (@..). We are going to remove links entirely and keep hashtags and mentions in case they signal something.","metadata":{}},{"cell_type":"code","source":"def clean_text(dataframe):\n    dataframe.text = dataframe.text.apply(lambda x: str.lower(x))\n    dataframe.text = dataframe.text.apply(lambda x: re.sub(r'http\\S+', '', x))\n    dataframe.text = dataframe.text.apply(lambda x: re.sub(r'#', '', x))\n    dataframe.text = dataframe.text.apply(lambda x: re.sub(r'\\W+', ' ', x))\n    dataframe.text = dataframe.text.apply(lambda x: re.sub(r'\\d+', '', x))\n    return(dataframe)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T11:42:59.938828Z","iopub.execute_input":"2023-07-17T11:42:59.939258Z","iopub.status.idle":"2023-07-17T11:42:59.946629Z","shell.execute_reply.started":"2023-07-17T11:42:59.939209Z","shell.execute_reply":"2023-07-17T11:42:59.945668Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"sample_train = clean_text(sample_train)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T11:43:02.427746Z","iopub.execute_input":"2023-07-17T11:43:02.428575Z","iopub.status.idle":"2023-07-17T11:43:02.436050Z","shell.execute_reply.started":"2023-07-17T11:43:02.428536Z","shell.execute_reply":"2023-07-17T11:43:02.435112Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"sample_train","metadata":{"execution":{"iopub.status.busy":"2023-07-17T11:43:03.948613Z","iopub.execute_input":"2023-07-17T11:43:03.949634Z","iopub.status.idle":"2023-07-17T11:43:03.960500Z","shell.execute_reply.started":"2023-07-17T11:43:03.949592Z","shell.execute_reply":"2023-07-17T11:43:03.959410Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"        id      keyword       location  \\\n4277  6075  heat%20wave     liverpool    \n6306  9009    stretcher            NaN   \n1075  1554         bomb            NaN   \n4011  5695       floods            NaN   \n4213  5985    hazardous  Nashville, Tn   \n\n                                                                                                          text  \\\n4277  greatbritishbakeoff love to know where i was when all this nice weather happened did miss the heat wave    \n6306                                                                         how to freeze fruits and veggies    \n1075                                         new documents found pointing to japan s wwii atomic bomb program    \n4011                                     children in myanmar face a double catastrophe as floods hit the most    \n4213                              wholesale we gon rep that hit at all costs hazardous wholeteam wholesaleent    \n\n      target  \n4277       0  \n6306       0  \n1075       1  \n4011       1  \n4213       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4277</th>\n      <td>6075</td>\n      <td>heat%20wave</td>\n      <td>liverpool</td>\n      <td>greatbritishbakeoff love to know where i was when all this nice weather happened did miss the heat wave</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6306</th>\n      <td>9009</td>\n      <td>stretcher</td>\n      <td>NaN</td>\n      <td>how to freeze fruits and veggies</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1075</th>\n      <td>1554</td>\n      <td>bomb</td>\n      <td>NaN</td>\n      <td>new documents found pointing to japan s wwii atomic bomb program</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4011</th>\n      <td>5695</td>\n      <td>floods</td>\n      <td>NaN</td>\n      <td>children in myanmar face a double catastrophe as floods hit the most</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4213</th>\n      <td>5985</td>\n      <td>hazardous</td>\n      <td>Nashville, Tn</td>\n      <td>wholesale we gon rep that hit at all costs hazardous wholeteam wholesaleent</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"clean_train = clean_text(train)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T11:43:06.238293Z","iopub.execute_input":"2023-07-17T11:43:06.238728Z","iopub.status.idle":"2023-07-17T11:43:06.409861Z","shell.execute_reply.started":"2023-07-17T11:43:06.238676Z","shell.execute_reply":"2023-07-17T11:43:06.408683Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_df, val_df = np.split(clean_train.sample(frac = 1), [int(0.8 * len(clean_train))])","metadata":{"execution":{"iopub.status.busy":"2023-07-17T11:43:08.665857Z","iopub.execute_input":"2023-07-17T11:43:08.666238Z","iopub.status.idle":"2023-07-17T11:43:08.675183Z","shell.execute_reply.started":"2023-07-17T11:43:08.666196Z","shell.execute_reply":"2023-07-17T11:43:08.674262Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Define and Train Model - First Model","metadata":{}},{"cell_type":"code","source":"tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'\ntfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_preprocess = hub.KerasLayer(tfhub_handle_preprocess)\nbert_encoder = hub.KerasLayer(tfhub_handle_encoder)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_input = tf.keras.layers.Input(shape = (), dtype = tf.string)\nencoder_input = bert_preprocess(text_input)\nencoder_output = bert_encoder(encoder_input)\n\nl = tf.keras.layers.Dense(100, activation = 'relu')(encoder_output['pooled_output'])\nl = tf.keras.layers.Dropout(0.3)(l)\nl = tf.keras.layers.Dense(25, activation = 'relu')(l)\nl = tf.keras.layers.Dropout(0.3)(l)\nl = tf.keras.layers.Dense(1, activation = 'sigmoid')(l)\n\nmodel = tf.keras.Model(inputs=[text_input], outputs = [l])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0005),\n              loss = tf.keras.losses.BinaryCrossentropy(),\n              metrics = ['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n                                                  patience = 2)\n\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath = 'model/best_performed_model.ckpt',\n    save_weights_only = True,\n    save_best_only = True,\n    monitor = 'val_loss',\n    verbose = 1\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T11:44:55.975867Z","iopub.execute_input":"2023-07-17T11:44:55.976896Z","iopub.status.idle":"2023-07-17T11:44:55.983000Z","shell.execute_reply.started":"2023-07-17T11:44:55.976853Z","shell.execute_reply":"2023-07-17T11:44:55.981955Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_df.text,\n                    train_df.target,\n                    validation_data = (val_df.text, val_df.target),\n                    epochs = 30,\n                    callbacks = [early_stopping, model_checkpoint_callback])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.legend(['training', 'validation'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Define and Train Model - Second Model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1'\ntfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_preprocess = hub.KerasLayer(tfhub_handle_preprocess)\nbert_encoder = hub.KerasLayer(tfhub_handle_encoder)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_input = tf.keras.layers.Input(shape = (), dtype = tf.string)\nencoder_input = bert_preprocess(text_input)\nencoder_output = bert_encoder(encoder_input)\n\nl = tf.keras.layers.Dense(16, activation = 'relu')(encoder_output['pooled_output'])\nl = tf.keras.layers.Dropout(0.3)(l)\nl = tf.keras.layers.Dense(1, activation = 'sigmoid')(l)\n\nmodel = tf.keras.Model(inputs=[text_input], outputs = [l])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0005),\n              loss = tf.keras.losses.BinaryCrossentropy(),\n              metrics = ['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_df.text,\n                    train_df.target,\n                    validation_data = (val_df.text, val_df.target),\n                    epochs = 30,\n                    callbacks = [early_stopping, model_checkpoint_callback])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define and Train Model - Third Model","metadata":{}},{"cell_type":"code","source":"tfhub_handle_encoder = 'https://tfhub.dev/google/electra_small/2'\ntfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'","metadata":{"execution":{"iopub.status.busy":"2023-07-17T11:44:05.134192Z","iopub.execute_input":"2023-07-17T11:44:05.135364Z","iopub.status.idle":"2023-07-17T11:44:05.139973Z","shell.execute_reply.started":"2023-07-17T11:44:05.135317Z","shell.execute_reply":"2023-07-17T11:44:05.138803Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"bert_preprocess = hub.KerasLayer(tfhub_handle_preprocess)\nbert_encoder = hub.KerasLayer(tfhub_handle_encoder)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T11:44:13.588745Z","iopub.execute_input":"2023-07-17T11:44:13.589115Z","iopub.status.idle":"2023-07-17T11:44:28.578380Z","shell.execute_reply.started":"2023-07-17T11:44:13.589086Z","shell.execute_reply":"2023-07-17T11:44:28.577207Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"text_input = tf.keras.layers.Input(shape = (), dtype = tf.string)\nencoder_input = bert_preprocess(text_input)\nencoder_output = bert_encoder(encoder_input)\n\nl = tf.keras.layers.Dense(32, activation = 'relu')(encoder_output['pooled_output'])\nl = tf.keras.layers.Dropout(0.3)(l)\nl = tf.keras.layers.Dense(16, activation = 'relu')(l)\nl = tf.keras.layers.Dropout(0.3)(l)\nl = tf.keras.layers.Dense(1, activation = 'sigmoid')(l)\n\nmodel = tf.keras.Model(inputs=[text_input], outputs = [l])","metadata":{"execution":{"iopub.status.busy":"2023-07-17T12:10:03.604835Z","iopub.execute_input":"2023-07-17T12:10:03.605855Z","iopub.status.idle":"2023-07-17T12:10:03.817210Z","shell.execute_reply.started":"2023-07-17T12:10:03.605813Z","shell.execute_reply":"2023-07-17T12:10:03.816089Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n              loss = tf.keras.losses.BinaryCrossentropy(),\n              metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-07-17T12:10:07.186147Z","iopub.execute_input":"2023-07-17T12:10:07.186528Z","iopub.status.idle":"2023-07-17T12:10:07.200960Z","shell.execute_reply.started":"2023-07-17T12:10:07.186499Z","shell.execute_reply":"2023-07-17T12:10:07.199568Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_df.text,\n                    train_df.target,\n                    validation_data = (val_df.text, val_df.target),\n                    epochs = 30,\n                    callbacks = [early_stopping, model_checkpoint_callback])","metadata":{"execution":{"iopub.status.busy":"2023-07-17T12:10:09.874566Z","iopub.execute_input":"2023-07-17T12:10:09.874936Z","iopub.status.idle":"2023-07-17T12:25:44.044735Z","shell.execute_reply.started":"2023-07-17T12:10:09.874908Z","shell.execute_reply":"2023-07-17T12:25:44.043430Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Epoch 1/30\n191/191 [==============================] - ETA: 0s - loss: 0.6400 - accuracy: 0.6399\nEpoch 1: val_loss did not improve from 0.58092\n191/191 [==============================] - 121s 617ms/step - loss: 0.6400 - accuracy: 0.6399 - val_loss: 0.6255 - val_accuracy: 0.6651\nEpoch 2/30\n191/191 [==============================] - ETA: 0s - loss: 0.6067 - accuracy: 0.6808\nEpoch 2: val_loss did not improve from 0.58092\n191/191 [==============================] - 116s 608ms/step - loss: 0.6067 - accuracy: 0.6808 - val_loss: 0.6127 - val_accuracy: 0.6704\nEpoch 3/30\n191/191 [==============================] - ETA: 0s - loss: 0.5846 - accuracy: 0.7094\nEpoch 3: val_loss did not improve from 0.58092\n191/191 [==============================] - 117s 612ms/step - loss: 0.5846 - accuracy: 0.7094 - val_loss: 0.5907 - val_accuracy: 0.6868\nEpoch 4/30\n191/191 [==============================] - ETA: 0s - loss: 0.5738 - accuracy: 0.7158\nEpoch 4: val_loss improved from 0.58092 to 0.58039, saving model to model/best_performed_model.ckpt\n191/191 [==============================] - 116s 608ms/step - loss: 0.5738 - accuracy: 0.7158 - val_loss: 0.5804 - val_accuracy: 0.6986\nEpoch 5/30\n191/191 [==============================] - ETA: 0s - loss: 0.5683 - accuracy: 0.7212\nEpoch 5: val_loss did not improve from 0.58039\n191/191 [==============================] - 116s 605ms/step - loss: 0.5683 - accuracy: 0.7212 - val_loss: 0.5971 - val_accuracy: 0.6855\nEpoch 6/30\n191/191 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.7269\nEpoch 6: val_loss improved from 0.58039 to 0.57437, saving model to model/best_performed_model.ckpt\n191/191 [==============================] - 117s 612ms/step - loss: 0.5662 - accuracy: 0.7269 - val_loss: 0.5744 - val_accuracy: 0.7091\nEpoch 7/30\n191/191 [==============================] - ETA: 0s - loss: 0.5542 - accuracy: 0.7345\nEpoch 7: val_loss did not improve from 0.57437\n191/191 [==============================] - 116s 607ms/step - loss: 0.5542 - accuracy: 0.7345 - val_loss: 0.5747 - val_accuracy: 0.7131\nEpoch 8/30\n191/191 [==============================] - ETA: 0s - loss: 0.5531 - accuracy: 0.7333\nEpoch 8: val_loss did not improve from 0.57437\n191/191 [==============================] - 116s 609ms/step - loss: 0.5531 - accuracy: 0.7333 - val_loss: 0.5909 - val_accuracy: 0.7104\n","output_type":"stream"}]}]}