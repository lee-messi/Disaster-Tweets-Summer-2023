{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-17T11:41:03.411739Z","iopub.status.busy":"2023-07-17T11:41:03.411399Z","iopub.status.idle":"2023-07-17T11:41:34.673481Z","shell.execute_reply":"2023-07-17T11:41:34.672281Z","shell.execute_reply.started":"2023-07-17T11:41:03.411712Z"},"trusted":true},"outputs":[],"source":["!pip install tensorflow --quiet\n","!pip install tensorflow-hub --quiet\n","!pip install tensorflow-text --quiet\n","!pip install transformers --quiet"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T11:41:36.493386Z","iopub.status.busy":"2023-07-17T11:41:36.492436Z","iopub.status.idle":"2023-07-17T11:42:16.741010Z","shell.execute_reply":"2023-07-17T11:42:16.740110Z","shell.execute_reply.started":"2023-07-17T11:41:36.493349Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'tensorflow'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-985fc40a206a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_text\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"]}],"source":["import os, re, random\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_text as text\n","\n","tf.get_logger().setLevel('ERROR')\n","pd.set_option('display.max_colwidth', None)\n","os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\""]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T11:42:29.147229Z","iopub.status.busy":"2023-07-17T11:42:29.146801Z","iopub.status.idle":"2023-07-17T11:42:34.207678Z","shell.execute_reply":"2023-07-17T11:42:34.206535Z","shell.execute_reply.started":"2023-07-17T11:42:29.147182Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["on TPU\n","REPLICAS:  8\n"]}],"source":["# CHANGED FOR TPU 1VM:\n","# Detect hardware, return appropriate distribution strategy\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu=\"local\") # \"local\" for 1VM TPU\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","    print(\"on TPU\")\n","except tf.errors.NotFoundError:\n","    print(\"not on TPU\")\n","    strategy = tf.distribute.MirroredStrategy()\n","    \n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"]},{"cell_type":"markdown","metadata":{},"source":["## Import Dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T11:42:37.485713Z","iopub.status.busy":"2023-07-17T11:42:37.485346Z","iopub.status.idle":"2023-07-17T11:42:37.554815Z","shell.execute_reply":"2023-07-17T11:42:37.553582Z","shell.execute_reply.started":"2023-07-17T11:42:37.485685Z"},"trusted":true},"outputs":[],"source":["train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\n","test = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T11:42:39.297478Z","iopub.status.busy":"2023-07-17T11:42:39.297054Z","iopub.status.idle":"2023-07-17T11:42:39.307253Z","shell.execute_reply":"2023-07-17T11:42:39.306276Z","shell.execute_reply.started":"2023-07-17T11:42:39.297445Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Index(['id', 'keyword', 'location', 'text', 'target'], dtype='object')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["train.columns"]},{"cell_type":"markdown","metadata":{},"source":["## Exploratory Data Analysis (EDA)"]},{"cell_type":"markdown","metadata":{},"source":["First, let's check if there are any mislabeled tweets inside the dataset. As we cannot manually inspect all tweets to see if the tweets have been correctly classifier, we are going to look for duplicate tweets and check that duplicates have been assigned to the same labels. "]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T11:42:41.892567Z","iopub.status.busy":"2023-07-17T11:42:41.892186Z","iopub.status.idle":"2023-07-17T11:42:41.901839Z","shell.execute_reply":"2023-07-17T11:42:41.900926Z","shell.execute_reply.started":"2023-07-17T11:42:41.892538Z"},"trusted":true},"outputs":[{"data":{"text/plain":["69"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["duplicates = train[train.duplicated('text')]\n","duplicates.text.nunique()"]},{"cell_type":"markdown","metadata":{},"source":["There are 69 duplicate tweets inside the training dataset. We are going to iterate through these duplicate tweets to see if these duplicate tweets have unmatching labels. Unmatching labels would indicate that the tweet(s) has been mislabeled. We are going to store the index of these \"problematic duplicates\" inside a list and use it to iterature through these tweets so that we can re-assigned the correct labels after inspecting them."]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T11:42:44.252251Z","iopub.status.busy":"2023-07-17T11:42:44.251183Z","iopub.status.idle":"2023-07-17T11:42:44.346100Z","shell.execute_reply":"2023-07-17T11:42:44.345088Z","shell.execute_reply.started":"2023-07-17T11:42:44.252197Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[4, 7, 12, 15, 24, 26, 33, 34, 35, 36, 38, 39, 42, 44, 46, 51, 55, 58]\n"]}],"source":["problematic_duplicates = []\n","\n","for i in range(duplicates.text.nunique()):\n","    duplicate_subset = train[train.text == duplicates.text.unique()[i]]\n","    if len(duplicate_subset) > 1 and duplicate_subset.target.nunique() == 2:\n","        problematic_duplicates.append(i)\n","        \n","print(problematic_duplicates)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T11:42:47.445134Z","iopub.status.busy":"2023-07-17T11:42:47.444695Z","iopub.status.idle":"2023-07-17T11:42:47.461456Z","shell.execute_reply":"2023-07-17T11:42:47.460261Z","shell.execute_reply.started":"2023-07-17T11:42:47.445101Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6614</th>\n","      <td>9470</td>\n","      <td>terrorism</td>\n","      <td>Jeddah_Saudi Arabia.</td>\n","      <td>In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6616</th>\n","      <td>9472</td>\n","      <td>terrorism</td>\n","      <td>Riyadh</td>\n","      <td>In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id    keyword              location  \\\n","6614  9470  terrorism  Jeddah_Saudi Arabia.   \n","6616  9472  terrorism                Riyadh   \n","\n","                                                                                                        text  \\\n","6614  In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!   \n","6616  In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!   \n","\n","      target  \n","6614       0  \n","6616       1  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["train[train.text == duplicates.text.unique()[58]]"]},{"cell_type":"markdown","metadata":{},"source":["Above is the 58th duplicate. We see that these tweets have unmatching labels despite their texts being identical. This tweet is not about an actual disaster, so we are going to correctly assign both tweets as not being about an actual disaster. This is going to look like this: "]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T11:42:50.306932Z","iopub.status.busy":"2023-07-17T11:42:50.306555Z","iopub.status.idle":"2023-07-17T11:42:50.323117Z","shell.execute_reply":"2023-07-17T11:42:50.321867Z","shell.execute_reply.started":"2023-07-17T11:42:50.306904Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6614</th>\n","      <td>9470</td>\n","      <td>terrorism</td>\n","      <td>Jeddah_Saudi Arabia.</td>\n","      <td>In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6616</th>\n","      <td>9472</td>\n","      <td>terrorism</td>\n","      <td>Riyadh</td>\n","      <td>In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id    keyword              location  \\\n","6614  9470  terrorism  Jeddah_Saudi Arabia.   \n","6616  9472  terrorism                Riyadh   \n","\n","                                                                                                        text  \\\n","6614  In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!   \n","6616  In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!   \n","\n","      target  \n","6614       0  \n","6616       0  "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["train.target = np.where(train.text == duplicates.text.unique()[58], 0, train.target)\n","train[train.text == duplicates.text.unique()[58]]"]},{"cell_type":"markdown","metadata":{},"source":["Let's repeat this task for all problematic duplicates after having identified the correct labels for each and every one of these problematic duplicates. We are going to store the correct labels inside a list and iterate through the problematic duplicates, assigning the correct labels one after the other."]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T11:42:53.326823Z","iopub.status.busy":"2023-07-17T11:42:53.326451Z","iopub.status.idle":"2023-07-17T11:42:53.355873Z","shell.execute_reply":"2023-07-17T11:42:53.354544Z","shell.execute_reply.started":"2023-07-17T11:42:53.326795Z"},"trusted":true},"outputs":[],"source":["target_list = [0,0,0,0,1,0,0,0,1,0,0,0,0,0,1,1,0,0]\n","\n","for problematic_index in range(len(problematic_duplicates)): \n","    train.target = np.where(train.text == duplicates.text.unique()[problematic_index], \n","                            target_list[problematic_index], train.target)"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocessing the Text"]},{"cell_type":"markdown","metadata":{},"source":["Before we use the text as input, we are going to perform some basic pre-processing. To identify the appropriate steps, let's look at some of the tweets."]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T11:42:57.305198Z","iopub.status.busy":"2023-07-17T11:42:57.304818Z","iopub.status.idle":"2023-07-17T11:42:57.319395Z","shell.execute_reply":"2023-07-17T11:42:57.318270Z","shell.execute_reply.started":"2023-07-17T11:42:57.305167Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4277</th>\n","      <td>6075</td>\n","      <td>heat%20wave</td>\n","      <td>liverpool</td>\n","      <td>#greatbritishbakeoff love to know where I was when all this nice weather happened! Did miss the heat wave ?? ??</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6306</th>\n","      <td>9009</td>\n","      <td>stretcher</td>\n","      <td>NaN</td>\n","      <td>How to Freeze Fruits and Veggies\\nhttp://t.co/MET0mtpr3S</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1075</th>\n","      <td>1554</td>\n","      <td>bomb</td>\n","      <td>NaN</td>\n","      <td>New Documents Found Pointing To Japan's WWII Atomic Bomb Program http://t.co/M9mowCMVNj</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4011</th>\n","      <td>5695</td>\n","      <td>floods</td>\n","      <td>NaN</td>\n","      <td>Children in Myanmar face a 'double catastrophe' as floods hit the most ... http://t.co/0jFNvAXFph</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4213</th>\n","      <td>5985</td>\n","      <td>hazardous</td>\n","      <td>Nashville, Tn</td>\n","      <td>Wholesale #WE Gon Rep That $hit At All Costs- Hazardous #WholeTeam3 #WholesaleEnt https://t.co/JWnXH9Q5ov</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id      keyword       location  \\\n","4277  6075  heat%20wave     liverpool    \n","6306  9009    stretcher            NaN   \n","1075  1554         bomb            NaN   \n","4011  5695       floods            NaN   \n","4213  5985    hazardous  Nashville, Tn   \n","\n","                                                                                                                 text  \\\n","4277  #greatbritishbakeoff love to know where I was when all this nice weather happened! Did miss the heat wave ?? ??   \n","6306                                                         How to Freeze Fruits and Veggies\\nhttp://t.co/MET0mtpr3S   \n","1075                          New Documents Found Pointing To Japan's WWII Atomic Bomb Program http://t.co/M9mowCMVNj   \n","4011                Children in Myanmar face a 'double catastrophe' as floods hit the most ... http://t.co/0jFNvAXFph   \n","4213        Wholesale #WE Gon Rep That $hit At All Costs- Hazardous #WholeTeam3 #WholesaleEnt https://t.co/JWnXH9Q5ov   \n","\n","      target  \n","4277       0  \n","6306       0  \n","1075       1  \n","4011       1  \n","4213       0  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["random.seed(1048596)\n","sample_train = train.sample(frac = 1).head(5)\n","sample_train"]},{"cell_type":"markdown","metadata":{},"source":["In the randomly selected tweets above, we see that the tweets contain links (http://...), hashtags (#..), and mentions (@..). We are going to remove links entirely and keep hashtags and mentions in case they signal something."]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T11:42:59.939258Z","iopub.status.busy":"2023-07-17T11:42:59.938828Z","iopub.status.idle":"2023-07-17T11:42:59.946629Z","shell.execute_reply":"2023-07-17T11:42:59.945668Z","shell.execute_reply.started":"2023-07-17T11:42:59.939209Z"},"trusted":true},"outputs":[],"source":["def clean_text(dataframe):\n","    dataframe.text = dataframe.text.apply(lambda x: str.lower(x))\n","    dataframe.text = dataframe.text.apply(lambda x: re.sub(r'http\\S+', '', x))\n","    dataframe.text = dataframe.text.apply(lambda x: re.sub(r'#', '', x))\n","    dataframe.text = dataframe.text.apply(lambda x: re.sub(r'\\W+', ' ', x))\n","    dataframe.text = dataframe.text.apply(lambda x: re.sub(r'\\d+', '', x))\n","    return(dataframe)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T11:43:02.428575Z","iopub.status.busy":"2023-07-17T11:43:02.427746Z","iopub.status.idle":"2023-07-17T11:43:02.436050Z","shell.execute_reply":"2023-07-17T11:43:02.435112Z","shell.execute_reply.started":"2023-07-17T11:43:02.428536Z"},"trusted":true},"outputs":[],"source":["sample_train = clean_text(sample_train)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T11:43:03.949634Z","iopub.status.busy":"2023-07-17T11:43:03.948613Z","iopub.status.idle":"2023-07-17T11:43:03.960500Z","shell.execute_reply":"2023-07-17T11:43:03.959410Z","shell.execute_reply.started":"2023-07-17T11:43:03.949592Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4277</th>\n","      <td>6075</td>\n","      <td>heat%20wave</td>\n","      <td>liverpool</td>\n","      <td>greatbritishbakeoff love to know where i was when all this nice weather happened did miss the heat wave</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6306</th>\n","      <td>9009</td>\n","      <td>stretcher</td>\n","      <td>NaN</td>\n","      <td>how to freeze fruits and veggies</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1075</th>\n","      <td>1554</td>\n","      <td>bomb</td>\n","      <td>NaN</td>\n","      <td>new documents found pointing to japan s wwii atomic bomb program</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4011</th>\n","      <td>5695</td>\n","      <td>floods</td>\n","      <td>NaN</td>\n","      <td>children in myanmar face a double catastrophe as floods hit the most</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4213</th>\n","      <td>5985</td>\n","      <td>hazardous</td>\n","      <td>Nashville, Tn</td>\n","      <td>wholesale we gon rep that hit at all costs hazardous wholeteam wholesaleent</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id      keyword       location  \\\n","4277  6075  heat%20wave     liverpool    \n","6306  9009    stretcher            NaN   \n","1075  1554         bomb            NaN   \n","4011  5695       floods            NaN   \n","4213  5985    hazardous  Nashville, Tn   \n","\n","                                                                                                          text  \\\n","4277  greatbritishbakeoff love to know where i was when all this nice weather happened did miss the heat wave    \n","6306                                                                         how to freeze fruits and veggies    \n","1075                                         new documents found pointing to japan s wwii atomic bomb program    \n","4011                                     children in myanmar face a double catastrophe as floods hit the most    \n","4213                              wholesale we gon rep that hit at all costs hazardous wholeteam wholesaleent    \n","\n","      target  \n","4277       0  \n","6306       0  \n","1075       1  \n","4011       1  \n","4213       0  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["sample_train"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T11:43:06.238728Z","iopub.status.busy":"2023-07-17T11:43:06.238293Z","iopub.status.idle":"2023-07-17T11:43:06.409861Z","shell.execute_reply":"2023-07-17T11:43:06.408683Z","shell.execute_reply.started":"2023-07-17T11:43:06.238676Z"},"trusted":true},"outputs":[],"source":["clean_train = clean_text(train)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T11:43:08.666238Z","iopub.status.busy":"2023-07-17T11:43:08.665857Z","iopub.status.idle":"2023-07-17T11:43:08.675183Z","shell.execute_reply":"2023-07-17T11:43:08.674262Z","shell.execute_reply.started":"2023-07-17T11:43:08.666196Z"},"trusted":true},"outputs":[],"source":["train_df, val_df = np.split(clean_train.sample(frac = 1), [int(0.8 * len(clean_train))])"]},{"cell_type":"markdown","metadata":{},"source":["## Define and Train Model - First Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'\n","tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["bert_preprocess = hub.KerasLayer(tfhub_handle_preprocess)\n","bert_encoder = hub.KerasLayer(tfhub_handle_encoder)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["text_input = tf.keras.layers.Input(shape = (), dtype = tf.string)\n","encoder_input = bert_preprocess(text_input)\n","encoder_output = bert_encoder(encoder_input)\n","\n","l = tf.keras.layers.Dense(100, activation = 'relu')(encoder_output['pooled_output'])\n","l = tf.keras.layers.Dropout(0.3)(l)\n","l = tf.keras.layers.Dense(25, activation = 'relu')(l)\n","l = tf.keras.layers.Dropout(0.3)(l)\n","l = tf.keras.layers.Dense(1, activation = 'sigmoid')(l)\n","\n","model = tf.keras.Model(inputs=[text_input], outputs = [l])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0005),\n","              loss = tf.keras.losses.BinaryCrossentropy(),\n","              metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T11:44:55.976896Z","iopub.status.busy":"2023-07-17T11:44:55.975867Z","iopub.status.idle":"2023-07-17T11:44:55.983000Z","shell.execute_reply":"2023-07-17T11:44:55.981955Z","shell.execute_reply.started":"2023-07-17T11:44:55.976853Z"},"trusted":true},"outputs":[],"source":["early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n","                                                  patience = 2)\n","\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath = 'model/best_performed_model.ckpt',\n","    save_weights_only = True,\n","    save_best_only = True,\n","    monitor = 'val_loss',\n","    verbose = 1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["history = model.fit(train_df.text,\n","                    train_df.target,\n","                    validation_data = (val_df.text, val_df.target),\n","                    epochs = 30,\n","                    callbacks = [early_stopping, model_checkpoint_callback])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.legend(['training', 'validation'])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Define and Train Model - Second Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1'\n","tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["bert_preprocess = hub.KerasLayer(tfhub_handle_preprocess)\n","bert_encoder = hub.KerasLayer(tfhub_handle_encoder)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["text_input = tf.keras.layers.Input(shape = (), dtype = tf.string)\n","encoder_input = bert_preprocess(text_input)\n","encoder_output = bert_encoder(encoder_input)\n","\n","l = tf.keras.layers.Dense(16, activation = 'relu')(encoder_output['pooled_output'])\n","l = tf.keras.layers.Dropout(0.3)(l)\n","l = tf.keras.layers.Dense(1, activation = 'sigmoid')(l)\n","\n","model = tf.keras.Model(inputs=[text_input], outputs = [l])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0005),\n","              loss = tf.keras.losses.BinaryCrossentropy(),\n","              metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["history = model.fit(train_df.text,\n","                    train_df.target,\n","                    validation_data = (val_df.text, val_df.target),\n","                    epochs = 30,\n","                    callbacks = [early_stopping, model_checkpoint_callback])"]},{"cell_type":"markdown","metadata":{},"source":["## Define and Train Model - Third Model"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T11:44:05.135364Z","iopub.status.busy":"2023-07-17T11:44:05.134192Z","iopub.status.idle":"2023-07-17T11:44:05.139973Z","shell.execute_reply":"2023-07-17T11:44:05.138803Z","shell.execute_reply.started":"2023-07-17T11:44:05.135317Z"},"trusted":true},"outputs":[],"source":["tfhub_handle_encoder = 'https://tfhub.dev/google/electra_small/2'\n","tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T11:44:13.589115Z","iopub.status.busy":"2023-07-17T11:44:13.588745Z","iopub.status.idle":"2023-07-17T11:44:28.578380Z","shell.execute_reply":"2023-07-17T11:44:28.577207Z","shell.execute_reply.started":"2023-07-17T11:44:13.589086Z"},"trusted":true},"outputs":[],"source":["bert_preprocess = hub.KerasLayer(tfhub_handle_preprocess)\n","bert_encoder = hub.KerasLayer(tfhub_handle_encoder)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T12:10:03.605855Z","iopub.status.busy":"2023-07-17T12:10:03.604835Z","iopub.status.idle":"2023-07-17T12:10:03.817210Z","shell.execute_reply":"2023-07-17T12:10:03.816089Z","shell.execute_reply.started":"2023-07-17T12:10:03.605813Z"},"trusted":true},"outputs":[],"source":["text_input = tf.keras.layers.Input(shape = (), dtype = tf.string)\n","encoder_input = bert_preprocess(text_input)\n","encoder_output = bert_encoder(encoder_input)\n","\n","l = tf.keras.layers.Dense(32, activation = 'relu')(encoder_output['pooled_output'])\n","l = tf.keras.layers.Dropout(0.3)(l)\n","l = tf.keras.layers.Dense(16, activation = 'relu')(l)\n","l = tf.keras.layers.Dropout(0.3)(l)\n","l = tf.keras.layers.Dense(1, activation = 'sigmoid')(l)\n","\n","model = tf.keras.Model(inputs=[text_input], outputs = [l])"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T12:10:07.186528Z","iopub.status.busy":"2023-07-17T12:10:07.186147Z","iopub.status.idle":"2023-07-17T12:10:07.200960Z","shell.execute_reply":"2023-07-17T12:10:07.199568Z","shell.execute_reply.started":"2023-07-17T12:10:07.186499Z"},"trusted":true},"outputs":[],"source":["model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n","              loss = tf.keras.losses.BinaryCrossentropy(),\n","              metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T12:10:09.874936Z","iopub.status.busy":"2023-07-17T12:10:09.874566Z","iopub.status.idle":"2023-07-17T12:25:44.044735Z","shell.execute_reply":"2023-07-17T12:25:44.043430Z","shell.execute_reply.started":"2023-07-17T12:10:09.874908Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","191/191 [==============================] - ETA: 0s - loss: 0.6400 - accuracy: 0.6399\n","Epoch 1: val_loss did not improve from 0.58092\n","191/191 [==============================] - 121s 617ms/step - loss: 0.6400 - accuracy: 0.6399 - val_loss: 0.6255 - val_accuracy: 0.6651\n","Epoch 2/30\n","191/191 [==============================] - ETA: 0s - loss: 0.6067 - accuracy: 0.6808\n","Epoch 2: val_loss did not improve from 0.58092\n","191/191 [==============================] - 116s 608ms/step - loss: 0.6067 - accuracy: 0.6808 - val_loss: 0.6127 - val_accuracy: 0.6704\n","Epoch 3/30\n","191/191 [==============================] - ETA: 0s - loss: 0.5846 - accuracy: 0.7094\n","Epoch 3: val_loss did not improve from 0.58092\n","191/191 [==============================] - 117s 612ms/step - loss: 0.5846 - accuracy: 0.7094 - val_loss: 0.5907 - val_accuracy: 0.6868\n","Epoch 4/30\n","191/191 [==============================] - ETA: 0s - loss: 0.5738 - accuracy: 0.7158\n","Epoch 4: val_loss improved from 0.58092 to 0.58039, saving model to model/best_performed_model.ckpt\n","191/191 [==============================] - 116s 608ms/step - loss: 0.5738 - accuracy: 0.7158 - val_loss: 0.5804 - val_accuracy: 0.6986\n","Epoch 5/30\n","191/191 [==============================] - ETA: 0s - loss: 0.5683 - accuracy: 0.7212\n","Epoch 5: val_loss did not improve from 0.58039\n","191/191 [==============================] - 116s 605ms/step - loss: 0.5683 - accuracy: 0.7212 - val_loss: 0.5971 - val_accuracy: 0.6855\n","Epoch 6/30\n","191/191 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.7269\n","Epoch 6: val_loss improved from 0.58039 to 0.57437, saving model to model/best_performed_model.ckpt\n","191/191 [==============================] - 117s 612ms/step - loss: 0.5662 - accuracy: 0.7269 - val_loss: 0.5744 - val_accuracy: 0.7091\n","Epoch 7/30\n","191/191 [==============================] - ETA: 0s - loss: 0.5542 - accuracy: 0.7345\n","Epoch 7: val_loss did not improve from 0.57437\n","191/191 [==============================] - 116s 607ms/step - loss: 0.5542 - accuracy: 0.7345 - val_loss: 0.5747 - val_accuracy: 0.7131\n","Epoch 8/30\n","191/191 [==============================] - ETA: 0s - loss: 0.5531 - accuracy: 0.7333\n","Epoch 8: val_loss did not improve from 0.57437\n","191/191 [==============================] - 116s 609ms/step - loss: 0.5531 - accuracy: 0.7333 - val_loss: 0.5909 - val_accuracy: 0.7104\n"]}],"source":["history = model.fit(train_df.text,\n","                    train_df.target,\n","                    validation_data = (val_df.text, val_df.target),\n","                    epochs = 30,\n","                    callbacks = [early_stopping, model_checkpoint_callback])"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"}},"nbformat":4,"nbformat_minor":4}
