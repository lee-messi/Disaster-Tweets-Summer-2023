# About this Repository
These are the notebooks that I worked on for [the Natural Language Processing with Disaster Tweets competition on Kaggle](https://www.kaggle.com/competitions/nlp-getting-started). As of July 24th, 2023, the best performing model has the score of 0.79742 (Rank: 528). 

## Notebooks
- **Disaster Tweets Classifier using BERT**: We train three different models using BERT and achieve ~78% validation accuracy. This is not impressive compared to the performance of other models that are on the leaderboard (Best score: 0.79742; Rank: 528; Submission on: July 20th, 2023).
