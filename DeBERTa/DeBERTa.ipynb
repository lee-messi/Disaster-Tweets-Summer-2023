{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Objective of the Notebook","metadata":{}},{"cell_type":"markdown","source":"The objective of this notebook is to fine-tune DeBERTa to classify disaster tweets. In the previous notebook (the forked notebook), I had established a machine learning pipeline that I can use when I am trying to fine-tune pre-trained models made available on Hugging Face. Here, we are going to simply modify the model that was fine-tuned in that notebook, from DistilBERT to DeBERTa (Decoding-enhanced BERT with Disentangled Attention). DeBERTa is known to perform significantly better in a wide variety of NLP tasks such as NLI and STS, so we expect this fine-tuned model to perform moderately better than the previous binary classifiers trained on BERTweet and DistilBERT. ","metadata":{}},{"cell_type":"code","source":"!pip install evaluate --quiet\n!pip install emoji --quiet","metadata":{"execution":{"iopub.status.busy":"2023-08-16T14:11:08.838475Z","iopub.execute_input":"2023-08-16T14:11:08.839385Z","iopub.status.idle":"2023-08-16T14:11:34.613374Z","shell.execute_reply.started":"2023-08-16T14:11:08.839338Z","shell.execute_reply":"2023-08-16T14:11:34.611928Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom emoji import demojize\nimport tensorflow_hub as hub\nimport matplotlib.pyplot as plt\nimport os, re, random, datasets, evaluate\nfrom sklearn.model_selection import train_test_split\n\npd.set_option('display.max_colwidth', None)\nfrom transformers import AutoTokenizer, TFAutoModel, EarlyStoppingCallback","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-16T14:11:37.686305Z","iopub.execute_input":"2023-08-16T14:11:37.686688Z","iopub.status.idle":"2023-08-16T14:11:56.132557Z","shell.execute_reply.started":"2023-08-16T14:11:37.686648Z","shell.execute_reply":"2023-08-16T14:11:56.131496Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-08-16T14:12:01.788441Z","iopub.execute_input":"2023-08-16T14:12:01.788986Z","iopub.status.idle":"2023-08-16T14:12:01.846755Z","shell.execute_reply.started":"2023-08-16T14:12:01.788941Z","shell.execute_reply":"2023-08-16T14:12:01.845595Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess the Data Sets","metadata":{}},{"cell_type":"markdown","source":"In the past few notebooks, I established a pre-processing pipeline where I: (1) identify misclassified tweets (duplicate tweets whose labels are not identical), (2) concatenate the substance of the location column with that of the text column, and (3) clean the tweets following the set of pre-processing steps that VinAI used prior to training the BERTweet model. You can read more about the pre-processing steps by taking a look at one of my previous notebooks [here](https://www.kaggle.com/code/l048596/disaster-tweets-bertweet-pytorch-ii-82-62?kernelSessionId=139348416). ","metadata":{}},{"cell_type":"code","source":"duplicates = train[train.duplicated('text')]\nproblematic_duplicates = []\n\nfor i in range(duplicates.text.nunique()):\n    duplicate_subset = train[train.text == duplicates.text.unique()[i]]\n    if len(duplicate_subset) > 1 and duplicate_subset.target.nunique() == 2:\n        problematic_duplicates.append(i)\n        \ntarget_list = [0,0,0,0,1,0,0,0,1,0,0,0,0,0,1,1,0,0]\n\nfor problematic_index in range(len(problematic_duplicates)): \n    train.target = np.where(train.text == duplicates.text.unique()[problematic_index], \n                            target_list[problematic_index], train.target)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T14:12:03.693101Z","iopub.execute_input":"2023-08-16T14:12:03.693463Z","iopub.status.idle":"2023-08-16T14:12:03.859103Z","shell.execute_reply.started":"2023-08-16T14:12:03.693436Z","shell.execute_reply":"2023-08-16T14:12:03.858095Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def clean_tweets(text):\n    \n    text = text.lower()\n    \n    text = text.replace(\"n't\", \" n't \")\n    text = text.replace(\"n 't\", \" n't \")\n    text = text.replace(\"ca n't\", \"can't\")\n    text = text.replace(\"ai n't\", \"ain't\")\n    \n    text = text.replace(\"'m\", \" 'm \")\n    text = text.replace(\"'re\", \" 're \")\n    text = text.replace(\"'s\", \" 's \")\n    text = text.replace(\"'ll\", \" 'll \")\n    text = text.replace(\"'d\", \" 'd \")\n    text = text.replace(\"'ve\", \" 've \")\n    text = text.replace(\"\\n\", \" \")\n    \n    text = text.replace(\" p . m .\", \" p.m.\")\n    text = text.replace(\" p . m \", \" p.m \")\n    text = text.replace(\" a . m .\", \" a.m.\")\n    text = text.replace(\" a . m \", \" a.m \")\n    \n    token_list = text.split(' ')\n    \n    token_list = [re.sub('#', '', x) for x in token_list]\n    token_list = [re.sub(r'@\\S+', '@USER', x) for x in token_list]\n    token_list = [re.sub(r'http\\S+', 'HTTPURL', x) for x in token_list]\n    token_list = [re.sub(r'www\\S+', 'HTTPURL', x) for x in token_list]\n    token_list = [demojize(x) if len(x) == 1 else x for x in token_list]\n    \n    return(\" \".join(token_list))","metadata":{"execution":{"iopub.status.busy":"2023-08-16T14:12:05.596313Z","iopub.execute_input":"2023-08-16T14:12:05.596680Z","iopub.status.idle":"2023-08-16T14:12:05.606406Z","shell.execute_reply.started":"2023-08-16T14:12:05.596645Z","shell.execute_reply":"2023-08-16T14:12:05.605376Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train.text = train.text.apply(lambda x: clean_tweets(x))\ntest_df.text = test_df.text.apply(lambda x: clean_tweets(x))","metadata":{"execution":{"iopub.status.busy":"2023-08-16T14:12:08.383233Z","iopub.execute_input":"2023-08-16T14:12:08.383596Z","iopub.status.idle":"2023-08-16T14:12:09.411346Z","shell.execute_reply.started":"2023-08-16T14:12:08.383567Z","shell.execute_reply":"2023-08-16T14:12:09.410386Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train = train.groupby('target').sample(np.min(train.target.value_counts().to_list())) # remove random state\ntrain_df, val_df = np.split(train.sample(frac = 1), [int(0.85 * len(train))])","metadata":{"execution":{"iopub.status.busy":"2023-08-16T14:12:10.654769Z","iopub.execute_input":"2023-08-16T14:12:10.655254Z","iopub.status.idle":"2023-08-16T14:12:10.678440Z","shell.execute_reply.started":"2023-08-16T14:12:10.655216Z","shell.execute_reply":"2023-08-16T14:12:10.677392Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Load Pre-trained Model for Tokenization","metadata":{}},{"cell_type":"code","source":"model_name = 'microsoft/deberta-v3-small'\n\ntokenizer = AutoTokenizer.from_pretrained(model_name, \n                                          normalization = True,\n                                          use_fast = False,\n                                          add_special_tokens = True,\n                                          pad_to_max_length = True, \n                                          return_attention_mask = True)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T14:12:29.538153Z","iopub.execute_input":"2023-08-16T14:12:29.538539Z","iopub.status.idle":"2023-08-16T14:12:31.133513Z","shell.execute_reply.started":"2023-08-16T14:12:29.538511Z","shell.execute_reply":"2023-08-16T14:12:31.132494Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8db84b4fe9464db0b5f7437af97165c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c1ba9ef2fa244419e224ed338d65c5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6a32f2834b6497aa9f31609ec764083"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"max_len = np.max([len(x) for x in train.text])","metadata":{"execution":{"iopub.status.busy":"2023-08-16T14:12:33.901893Z","iopub.execute_input":"2023-08-16T14:12:33.902632Z","iopub.status.idle":"2023-08-16T14:12:33.910884Z","shell.execute_reply.started":"2023-08-16T14:12:33.902599Z","shell.execute_reply":"2023-08-16T14:12:33.909796Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_tokens = tokenizer(train_df.text.to_list(),\n                         padding = \"max_length\",\n                         max_length = max_len,\n                         truncation = True).data\n\nval_tokens = tokenizer(val_df.text.to_list(),\n                       padding = \"max_length\",\n                       max_length = max_len,\n                       truncation = True).data","metadata":{"execution":{"iopub.status.busy":"2023-08-16T14:12:35.919800Z","iopub.execute_input":"2023-08-16T14:12:35.920189Z","iopub.status.idle":"2023-08-16T14:12:37.779109Z","shell.execute_reply.started":"2023-08-16T14:12:35.920156Z","shell.execute_reply":"2023-08-16T14:12:37.778111Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def extract_features(tokens, labels, batch_size = 16): # Note that batch size of 64 willr esult in GPU OOM error\n    features = {x: tokens[x] for x in tokenizer.model_input_names}\n    features = tf.data.Dataset.from_tensor_slices((features, labels))\n    return features.shuffle(len(labels)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\ntrain_features = extract_features(train_tokens, train_df.target)\nval_features = extract_features(val_tokens, val_df.target)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T14:12:38.829608Z","iopub.execute_input":"2023-08-16T14:12:38.830122Z","iopub.status.idle":"2023-08-16T14:12:57.990422Z","shell.execute_reply.started":"2023-08-16T14:12:38.830042Z","shell.execute_reply":"2023-08-16T14:12:57.989445Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"bert_model = TFAutoModel.from_pretrained(model_name)\ntext = [\"Replace me by any text you'd like.\", \"My name is Messi Lee\"]\n\nencoded_input = tokenizer(text, \n                          padding = \"max_length\", \n                          max_length = max_len,\n                          truncation = True,\n                          return_tensors='tf')\n\n# encoded_input\noutput = bert_model([encoded_input['input_ids'], encoded_input['attention_mask']])\noutput","metadata":{"execution":{"iopub.status.busy":"2023-08-16T14:15:18.265872Z","iopub.execute_input":"2023-08-16T14:15:18.266418Z","iopub.status.idle":"2023-08-16T14:15:20.046911Z","shell.execute_reply.started":"2023-08-16T14:15:18.266376Z","shell.execute_reply":"2023-08-16T14:15:20.045735Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"All model checkpoint layers were used when initializing TFDebertaV2Model.\n\nAll the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-small.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TFBaseModelOutput(last_hidden_state=<tf.Tensor: shape=(2, 159, 768), dtype=float32, numpy=\narray([[[-8.21725652e-03,  9.34619643e-03, -3.16984877e-02, ...,\n         -7.06309378e-02, -3.45765762e-02, -8.09677467e-02],\n        [-1.04211187e+00, -2.73463845e-01,  1.55843809e-01, ...,\n          4.24775302e-01,  5.86446047e-01,  4.63497162e-01],\n        [ 4.20123369e-01, -1.39614537e-01, -2.98552603e-01, ...,\n          2.81707257e-01, -2.22064167e-01, -1.91090941e-01],\n        ...,\n        [-5.77143192e-01, -2.09147632e-02,  1.35440663e-01, ...,\n         -2.57291123e-02, -3.41671556e-01, -1.85759217e-01],\n        [-5.77143192e-01, -2.09147632e-02,  1.35440663e-01, ...,\n         -2.57291123e-02, -3.41671556e-01, -1.85759217e-01],\n        [-5.77143192e-01, -2.09147632e-02,  1.35440663e-01, ...,\n         -2.57291123e-02, -3.41671556e-01, -1.85759217e-01]],\n\n       [[ 1.24452747e-02, -3.14728394e-02,  1.28026213e-03, ...,\n         -6.23275191e-02, -5.48804179e-02, -5.14611900e-02],\n        [-5.07370114e-01, -5.01993075e-02,  3.22522432e-01, ...,\n          7.77145982e-01,  6.90992713e-01,  2.33067885e-01],\n        [-2.60883665e+00, -4.69101667e-01,  4.05494273e-02, ...,\n          7.50458598e-01,  6.01820350e-01, -1.12841964e-01],\n        ...,\n        [-5.77143192e-01, -2.09147632e-02,  1.35440663e-01, ...,\n         -2.57291123e-02, -3.41671556e-01, -1.85759217e-01],\n        [-5.77143192e-01, -2.09147632e-02,  1.35440663e-01, ...,\n         -2.57291123e-02, -3.41671556e-01, -1.85759217e-01],\n        [-5.77143192e-01, -2.09147632e-02,  1.35440663e-01, ...,\n         -2.57291123e-02, -3.41671556e-01, -1.85759217e-01]]],\n      dtype=float32)>, hidden_states=None, attentions=None)"},"metadata":{}}]},{"cell_type":"markdown","source":"The last hidden state of the DeBERTa model is of shape (2, 159, 768). The 2 corresponds to the (None, ???, ???) of the bert_model layer as shown in the model summary (the number of observations), the 159 corresponds to the length of the text (in this case, the texts were truncated to the length of *max_len* which is 159), and 768 corresponds to the dimension of the DeBERTa embeddings. I wanted to keep the change from the previous notebook minimal, but here I tokenized the texts to the maximum length of all texts inside the training data set (159), so that ended up shrinking the second dimensions of the input from 512 to 159. ","metadata":{}},{"cell_type":"code","source":"bert_model = TFAutoModel.from_pretrained(model_name)\n\ninput_ids = tf.keras.Input(shape=(max_len,), dtype = 'int32', name = 'input_ids')\nattention_masks = tf.keras.Input(shape=(max_len,), dtype ='int32', name = 'attention_mask')\n\noutput = bert_model([input_ids, attention_masks])[0]\noutput = tf.keras.layers.Dropout(0.7)(output)\noutput = tf.keras.layers.Flatten()(output)\noutput = tf.keras.layers.Dense(1, activation = 'sigmoid')(output)\n\nmodel = tf.keras.models.Model(inputs = [input_ids, attention_masks], outputs = output)\n\nmodel.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-5), \n              loss = tf.keras.losses.BinaryCrossentropy(), \n              metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-08-16T14:18:29.128507Z","iopub.execute_input":"2023-08-16T14:18:29.129120Z","iopub.status.idle":"2023-08-16T14:18:32.680630Z","shell.execute_reply.started":"2023-08-16T14:18:29.129077Z","shell.execute_reply":"2023-08-16T14:18:32.679627Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"All model checkpoint layers were used when initializing TFDebertaV2Model.\n\nAll the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-small.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T14:18:33.366021Z","iopub.execute_input":"2023-08-16T14:18:33.366443Z","iopub.status.idle":"2023-08-16T14:18:33.412343Z","shell.execute_reply.started":"2023-08-16T14:18:33.366414Z","shell.execute_reply":"2023-08-16T14:18:33.411356Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Model: \"model_4\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_ids (InputLayer)         [(None, 159)]        0           []                               \n                                                                                                  \n attention_mask (InputLayer)    [(None, 159)]        0           []                               \n                                                                                                  \n tf_deberta_v2_model_7 (TFDeber  TFBaseModelOutput(l  141304320  ['input_ids[0][0]',              \n taV2Model)                     ast_hidden_state=(N               'attention_mask[0][0]']         \n                                one, 159, 768),                                                   \n                                 hidden_states=None                                               \n                                , attentions=None)                                                \n                                                                                                  \n dropout_4 (Dropout)            (None, 159, 768)     0           ['tf_deberta_v2_model_7[0][0]']  \n                                                                                                  \n flatten_4 (Flatten)            (None, 122112)       0           ['dropout_4[0][0]']              \n                                                                                                  \n dense_4 (Dense)                (None, 1)            122113      ['flatten_4[0][0]']              \n                                                                                                  \n==================================================================================================\nTotal params: 141,426,433\nTrainable params: 141,426,433\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n                                                  patience = 2)\n\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath = 'model/best_performed_model',\n    save_weights_only = True,\n    save_best_only = True,\n    monitor = 'val_loss',\n    verbose = 1\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T14:18:35.830186Z","iopub.execute_input":"2023-08-16T14:18:35.830593Z","iopub.status.idle":"2023-08-16T14:18:35.837170Z","shell.execute_reply.started":"2023-08-16T14:18:35.830563Z","shell.execute_reply":"2023-08-16T14:18:35.835932Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model.fit(train_features, \n          validation_data = val_features,\n          epochs = 30, \n          callbacks = [early_stopping, model_checkpoint_callback])","metadata":{"execution":{"iopub.status.busy":"2023-08-16T14:18:38.113247Z","iopub.execute_input":"2023-08-16T14:18:38.113617Z","iopub.status.idle":"2023-08-16T14:34:15.826892Z","shell.execute_reply.started":"2023-08-16T14:18:38.113588Z","shell.execute_reply":"2023-08-16T14:34:15.825711Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch 1/30\n346/346 [==============================] - ETA: 0s - loss: 0.8935 - accuracy: 0.6432\nEpoch 1: val_loss improved from inf to 0.46172, saving model to model/best_performed_model\n346/346 [==============================] - 209s 509ms/step - loss: 0.8935 - accuracy: 0.6432 - val_loss: 0.4617 - val_accuracy: 0.8045\nEpoch 2/30\n346/346 [==============================] - ETA: 0s - loss: 0.6381 - accuracy: 0.7624\nEpoch 2: val_loss improved from 0.46172 to 0.45008, saving model to model/best_performed_model\n346/346 [==============================] - 169s 489ms/step - loss: 0.6381 - accuracy: 0.7624 - val_loss: 0.4501 - val_accuracy: 0.8199\nEpoch 3/30\n346/346 [==============================] - ETA: 0s - loss: 0.5326 - accuracy: 0.8089\nEpoch 3: val_loss improved from 0.45008 to 0.44797, saving model to model/best_performed_model\n346/346 [==============================] - 169s 488ms/step - loss: 0.5326 - accuracy: 0.8089 - val_loss: 0.4480 - val_accuracy: 0.8209\nEpoch 4/30\n346/346 [==============================] - ETA: 0s - loss: 0.4768 - accuracy: 0.8287\nEpoch 4: val_loss did not improve from 0.44797\n346/346 [==============================] - 156s 451ms/step - loss: 0.4768 - accuracy: 0.8287 - val_loss: 0.5003 - val_accuracy: 0.8342\nEpoch 5/30\n346/346 [==============================] - ETA: 0s - loss: 0.3867 - accuracy: 0.8641\nEpoch 5: val_loss did not improve from 0.44797\n346/346 [==============================] - 155s 449ms/step - loss: 0.3867 - accuracy: 0.8641 - val_loss: 0.5737 - val_accuracy: 0.8188\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x79987ec7f370>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Prepare for Submission","metadata":{}},{"cell_type":"markdown","source":"Here, we are simply loading the weights that were saved to *model/best_performed_model* during the training of the model. If the correct model is loaded, we would expect the loaded model to show 82.09% validation accuracy, which is the highest validation accuracy that we achieved during the training of the model. And we confirm that the evaluation yields the validation accuracy value that we expected to see. ","metadata":{}},{"cell_type":"code","source":"model.load_weights('model/best_performed_model')\nmodel.evaluate(val_features)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T14:34:20.375833Z","iopub.execute_input":"2023-08-16T14:34:20.376454Z","iopub.status.idle":"2023-08-16T14:35:15.054218Z","shell.execute_reply.started":"2023-08-16T14:34:20.376407Z","shell.execute_reply":"2023-08-16T14:35:15.053104Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"62/62 [==============================] - 7s 118ms/step - loss: 0.4480 - accuracy: 0.8209\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"[0.44796693325042725, 0.8208802342414856]"},"metadata":{}}]},{"cell_type":"code","source":"test_token = tokenizer(test_df.text.tolist(), \n                       padding = \"max_length\", \n                       max_length = max_len,\n                       truncation = True,\n                       return_tensors='tf').data","metadata":{"execution":{"iopub.status.busy":"2023-08-16T14:36:40.078118Z","iopub.execute_input":"2023-08-16T14:36:40.078657Z","iopub.status.idle":"2023-08-16T14:36:40.866474Z","shell.execute_reply.started":"2023-08-16T14:36:40.078626Z","shell.execute_reply":"2023-08-16T14:36:40.865398Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(test_token)\npred = [(x > 0.5).astype(int)[0] for x in predictions]","metadata":{"execution":{"iopub.status.busy":"2023-08-16T14:36:42.711359Z","iopub.execute_input":"2023-08-16T14:36:42.711735Z","iopub.status.idle":"2023-08-16T14:37:27.121611Z","shell.execute_reply.started":"2023-08-16T14:36:42.711703Z","shell.execute_reply":"2023-08-16T14:37:27.120488Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"102/102 [==============================] - 27s 229ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"submission = pd.DataFrame(list(zip(test_df.id, pred)), columns = [\"id\", \"target\"])\nsubmission.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T14:37:36.802405Z","iopub.execute_input":"2023-08-16T14:37:36.802799Z","iopub.status.idle":"2023-08-16T14:37:36.850720Z","shell.execute_reply.started":"2023-08-16T14:37:36.802757Z","shell.execute_reply":"2023-08-16T14:37:36.849768Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"The model achieved test accuracy of 81.64%. Despite DeBERTa being known to perform significantly better in a wide variety of tasks compared to other pre-trained models, simply switching out models from DistilBERT and BERTweet to DeBERTa did not significantly improvement the performance of our classifier. Here I speculate a few possible reasons for why this is the case:\n\n- The data pre-processing pipeline that I am using here is a set of steps that was adapted from BERTweet model. It may be that there is a pre-processing pipeline that is more suitable for the purpose of fine-tuning DeBERTa. \n- Given the unique nature of the text that we are classifying here, Tweets, BERTweet model fine-tuned on Twitter data may be more appropriate for training a classifier. \n- Let me know in the discussion if there are other reasons for why this may be the case or if I have made any mistakes in the notebook. Thanks. ","metadata":{}}]}